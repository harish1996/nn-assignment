{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00669285, 0.01798621, 0.04742587, 0.11920292, 0.26894142,\n",
       "       0.5       , 0.73105858, 0.88079708, 0.95257413, 0.98201379])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( range(-5,5) )\n",
    "1/(1+np.exp( -a ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    \n",
    "    def __init__():\n",
    "        self.a = 1\n",
    "    \n",
    "    def get():\n",
    "        return a\n",
    "    \n",
    "    def put(b):\n",
    "        a=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals().get(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Activation(object):\n",
    "\tdef _apply_activation( self, before_activation ):\n",
    "\t\tpass\n",
    "\n",
    "\t# Allows directly calling _apply_activation through the\n",
    "\t# object.\n",
    "\tdef __call__(self, before_activation ):\n",
    "\t\treturn self._apply_activation(before_activation)\n",
    "\n",
    "class DifferentiableActivation(Activation):\n",
    "\tdef backpropogate( self, Y ):\n",
    "\t\tpass\n",
    "\n",
    "class ReLU(DifferentiableActivation):\n",
    "\tdef _apply_activation( self,before_activation ):\n",
    "\t\tcpy = np.array( before_activation )\n",
    "\t\tcpy[ before_activation < 0 ] = 0\n",
    "\t\treturn cpy\n",
    "\n",
    "\tdef backpropogate( self, before_activation ):\n",
    "\t\tcpy = np.array( before_activation )\n",
    "\t\tcpy[ before_activation < 0 ] = 0\n",
    "\t\tcpy[ before_activation >= 0 ] = 1\n",
    "\t\treturn cpy\t\t\n",
    "\n",
    "\n",
    "class Signum(Activation):\n",
    "\tdef _apply_activation( self,before_activation ):\n",
    "\t\tcpy = np.array( before_activation )\n",
    "\t\tcpy[ before_activation < 0 ] = -1\n",
    "\t\tcpy[ before_activation >= 0 ] = 1\n",
    "\t\treturn cpy\n",
    "\n",
    "class Linear(DifferentiableActivation):\n",
    "\tdef _apply_activation(self,before_activation):\n",
    "\t\treturn before_activation\n",
    "\n",
    "\tdef backpropogate( self, before_activation ):\n",
    "\t\treturn np.ones_like(before_activation)\n",
    "\n",
    "class Sigmoid(DifferentiableActivation):\n",
    "\n",
    "\tdef _apply_activation( self, before_activation ):\n",
    "\t\treturn 1/( 1+np.exp(-before_activation) )\n",
    "\n",
    "\tdef backpropogate( self, before_activation ):\n",
    "\t\tsigma = self._apply_activation( before_activation )\n",
    "\t\treturn sigma*(1-sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signum = Signum\n",
    "sigmoid = Sigmoid\n",
    "linear = Linear\n",
    "relu = ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Signum"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals().get(\"signum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.ReLU, __main__.Linear, __main__.Sigmoid]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DifferentiableActivation.__subclasses__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Sigmoid.backpropogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(DifferentiableActivation,Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_column( x ):\n",
    "    return np.append( np.ones( (x.shape[0],1)), x, axis = 1)\n",
    "def loss( y, pred ):\n",
    "    return 0.5*( pred - y )**2\n",
    "def grad_loss( y, pred):\n",
    "    return ( pred - y )\n",
    "sig = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_1 = np.random.normal( size=(3,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40290924,  0.19902549],\n",
       "       [-0.2151213 ,  1.47257406],\n",
       "       [ 1.5275916 , -0.52832998]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_2 = np.random.normal( size=((3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array( [[1,0,0],[1,0,1],[1,1,0],[1,1,1] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_in = sig(inp.dot(in_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_in = add_bias_column( l1_in )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02035295]\n",
      " [ 0.12143282]\n",
      " [ 0.10140679]\n",
      " [ 0.27292674]] [[0.49491194]\n",
      " [0.53032096]\n",
      " [0.52532999]\n",
      " [0.56781127]]\n"
     ]
    }
   ],
   "source": [
    "l2_=  l1_in.dot(_1_2)\n",
    "pred = sig(l2_)\n",
    "print(l2_,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array( [[1,0,0,1]] ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12755697],\n",
       "       [0.14062016],\n",
       "       [0.1379858 ],\n",
       "       [0.09339355]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "los = loss( out, pred )\n",
    "los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87239559],\n",
       "       [ 0.12200759],\n",
       "       [ 0.17229281],\n",
       "       [-0.84041377]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = grad_loss(out,pred)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0971164 ],\n",
       "       [ 0.01306967],\n",
       "       [ 0.02457033],\n",
       "       [-0.11271501]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_2 = sig.backpropogate( l2_ )*grad\n",
    "grad_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17219141],\n",
       "       [-0.13890756],\n",
       "       [-0.09532941]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_2_inc = l1_in.T.dot( grad_2 )\n",
    "_1_2_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 5\n",
    "input_size = 4\n",
    "W = np.random.normal( size= (nodes,input_size+1) ) #set of 0 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4616709 , -1.31782198,  1.78769536,  0.32949272],\n",
       "       [-1.06728332, -0.22657353,  0.27176878, -0.70490441],\n",
       "       [-0.65734813, -0.05373732,  1.5917301 , -1.20728245],\n",
       "       [-1.34288337,  0.70695219, -0.36953573,  1.78571074],\n",
       "       [-0.61719113,  0.84638475, -1.46214583, -1.358602  ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(7,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
